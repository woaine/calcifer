{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import sys\n",
    "src_root = os.path.abspath(os.path.join(os.getcwd(), '../src'))\n",
    "if src_root not in sys.path:\n",
    "    sys.path.append(src_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the external dataset\n",
    "def load_data(filepath, name):\n",
    "    df = pd.read_csv(filepath)\n",
    "    print(f\"{name} data loaded successfully with {df.shape[0]} rows and {df.shape[1]} columns.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardized preprocessed external data loaded successfully with 6000 rows and 13 columns.\n",
      "standardized preprocessed augmented data loaded successfully with 6000 rows and 13 columns.\n",
      "standardized non_processed external data loaded successfully with 6000 rows and 13 columns.\n",
      "standardized non_processed augmented data loaded successfully with 6000 rows and 13 columns.\n",
      "normalized preprocessed external data loaded successfully with 6000 rows and 13 columns.\n",
      "normalized preprocessed augmented data loaded successfully with 6000 rows and 13 columns.\n",
      "normalized non_processed external data loaded successfully with 6000 rows and 13 columns.\n",
      "normalized non_processed augmented data loaded successfully with 6000 rows and 13 columns.\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "data = {}\n",
    "for (scale, preprocessing, data_type) in product(['standardized', 'normalized'], ['preprocessed', 'non_processed'], ['external', 'augmented']):\n",
    "    df = load_data(f\"../reports/results/training/{scale}/non_engineered/{preprocessing}/{data_type}/cv_history.csv\", scale+' '+preprocessing+' '+data_type)\n",
    "\n",
    "    data[(scale, preprocessing, data_type)] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mda import filter_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### External Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epochs per model:\n",
      "            layers activation  batch_size  epoch      loss       mae  \\\n",
      "223           [16]       relu          32    224  0.243459  0.255285   \n",
      "501           [16]       relu          64    202  0.245398  0.256097   \n",
      "814           [16]      prelu          32    215  0.242237  0.255664   \n",
      "1147          [16]      prelu          64    248  0.241833  0.255468   \n",
      "1497          [32]       relu          32    298  0.237544  0.253197   \n",
      "1792          [32]       relu          64    293  0.236376  0.252511   \n",
      "2070          [32]      prelu          32    271  0.237165  0.253005   \n",
      "2390          [32]      prelu          64    291  0.235855  0.253284   \n",
      "2672          [64]       relu          32    273  0.230161  0.249906   \n",
      "2982          [64]       relu          64    283  0.231417  0.250355   \n",
      "3297          [64]      prelu          32    298  0.230252  0.250754   \n",
      "3585          [64]      prelu          64    286  0.231097  0.250290   \n",
      "3876      [32, 16]       relu          32    277  0.244256  0.253954   \n",
      "4185      [32, 16]       relu          64    286  0.244894  0.253317   \n",
      "4469      [32, 16]      prelu          32    270  0.241416  0.253530   \n",
      "4782      [32, 16]      prelu          64    283  0.241064  0.253996   \n",
      "5068  [64, 32, 16]       relu          32    269  0.241149  0.251099   \n",
      "5392  [64, 32, 16]       relu          64    293  0.238028  0.249414   \n",
      "5697  [64, 32, 16]      prelu          32    298  0.235739  0.249962   \n",
      "5988  [64, 32, 16]      prelu          64    289  0.236044  0.248909   \n",
      "\n",
      "      r2_score  root_mean_squared_error  val_loss   val_mae  val_r2_score  \\\n",
      "223   0.518830                 0.348198  0.226461  0.245139      0.543603   \n",
      "501   0.514546                 0.349624  0.225073  0.244869      0.545348   \n",
      "814   0.521301                 0.347330  0.225507  0.245232      0.544718   \n",
      "1147  0.520674                 0.347469  0.224461  0.245146      0.545010   \n",
      "1497  0.529583                 0.344146  0.225569  0.245393      0.543166   \n",
      "1792  0.532067                 0.343404  0.224889  0.245185      0.543960   \n",
      "2070  0.530620                 0.343818  0.225260  0.245261      0.543562   \n",
      "2390  0.533246                 0.342864  0.224103  0.244872      0.545898   \n",
      "2672  0.543901                 0.338945  0.224893  0.245108      0.543276   \n",
      "2982  0.541410                 0.339907  0.225154  0.245443      0.542823   \n",
      "3297  0.543114                 0.339294  0.223218  0.244644      0.546351   \n",
      "3585  0.541593                 0.339699  0.225044  0.245527      0.543195   \n",
      "3876  0.522917                 0.346531  0.226263  0.242552      0.549206   \n",
      "4185  0.523550                 0.346439  0.228583  0.243307      0.546055   \n",
      "4469  0.528973                 0.344490  0.226242  0.243178      0.549372   \n",
      "4782  0.530300                 0.344036  0.226674  0.242855      0.549093   \n",
      "5068  0.536515                 0.341693  0.234066  0.243873      0.541958   \n",
      "5392  0.542932                 0.339285  0.237745  0.245661      0.535998   \n",
      "5697  0.544099                 0.338841  0.232432  0.244231      0.542680   \n",
      "5988  0.545847                 0.338187  0.234137  0.244778      0.540847   \n",
      "\n",
      "      val_root_mean_squared_error  learning_rate  \n",
      "223                      0.334632       0.000266  \n",
      "501                      0.333807       0.000331  \n",
      "814                      0.334012       0.000200  \n",
      "1147                     0.333804       0.000163  \n",
      "1497                     0.334480       0.000128  \n",
      "1792                     0.334077       0.000061  \n",
      "2070                     0.334214       0.000244  \n",
      "2390                     0.333348       0.000048  \n",
      "2672                     0.334270       0.000113  \n",
      "2982                     0.334463       0.000084  \n",
      "3297                     0.333238       0.000258  \n",
      "3585                     0.334426       0.000069  \n",
      "3876                     0.332339       0.000350  \n",
      "4185                     0.333455       0.000102  \n",
      "4469                     0.332319       0.000453  \n",
      "4782                     0.332398       0.000216  \n",
      "5068                     0.335236       0.000606  \n",
      "5392                     0.337714       0.000081  \n",
      "5697                     0.335152       0.000188  \n",
      "5988                     0.335637       0.000156  \n",
      "Best epochs per model:\n",
      "            layers activation  batch_size  epoch      loss       mae  \\\n",
      "266           [16]       relu          32    267  0.257568  0.260059   \n",
      "566           [16]       relu          64    267  0.254034  0.258786   \n",
      "886           [16]      prelu          32    287  0.253880  0.259016   \n",
      "1169          [16]      prelu          64    270  0.253881  0.259391   \n",
      "1471          [32]       relu          32    272  0.248916  0.257053   \n",
      "1787          [32]       relu          64    288  0.249540  0.256921   \n",
      "2088          [32]      prelu          32    289  0.247639  0.256646   \n",
      "2391          [32]      prelu          64    292  0.249207  0.256826   \n",
      "2697          [64]       relu          32    298  0.244016  0.255329   \n",
      "2999          [64]       relu          64    300  0.244528  0.255234   \n",
      "3294          [64]      prelu          32    295  0.244581  0.255629   \n",
      "3570          [64]      prelu          64    271  0.243820  0.254278   \n",
      "3885      [32, 16]       relu          32    286  0.261014  0.260989   \n",
      "4172      [32, 16]       relu          64    273  0.260329  0.259595   \n",
      "4498      [32, 16]      prelu          32    299  0.258247  0.260434   \n",
      "4782      [32, 16]      prelu          64    283  0.257152  0.259074   \n",
      "5082  [64, 32, 16]       relu          32    283  0.253412  0.256576   \n",
      "5393  [64, 32, 16]       relu          64    294  0.254879  0.256138   \n",
      "5680  [64, 32, 16]      prelu          32    281  0.252883  0.257080   \n",
      "5991  [64, 32, 16]      prelu          64    292  0.249720  0.255133   \n",
      "\n",
      "      r2_score  root_mean_squared_error  val_loss   val_mae  val_r2_score  \\\n",
      "266   0.497369                 0.361144  0.240050  0.250595      0.531499   \n",
      "566   0.503090                 0.359006  0.239701  0.250321      0.530690   \n",
      "886   0.504013                 0.358707  0.239198  0.251529      0.532207   \n",
      "1169  0.503808                 0.358777  0.239274  0.250688      0.532019   \n",
      "1471  0.513894                 0.355103  0.239322  0.250897      0.532304   \n",
      "1787  0.512291                 0.355697  0.239633  0.250985      0.531369   \n",
      "2088  0.515734                 0.354418  0.239211  0.251204      0.532081   \n",
      "2391  0.513197                 0.355375  0.239142  0.251144      0.532507   \n",
      "2697  0.522703                 0.351884  0.239393  0.251239      0.531388   \n",
      "2999  0.521965                 0.352168  0.239388  0.251410      0.531528   \n",
      "3294  0.521867                 0.352177  0.239086  0.251584      0.532053   \n",
      "3570  0.523259                 0.351669  0.239461  0.251395      0.531302   \n",
      "3885  0.496310                 0.361425  0.243633  0.251230      0.529388   \n",
      "4172  0.499445                 0.360373  0.244951  0.250166      0.528037   \n",
      "4498  0.501865                 0.359497  0.242699  0.250768      0.531359   \n",
      "4782  0.503457                 0.358901  0.241918  0.250348      0.532800   \n",
      "5082  0.517919                 0.353639  0.248905  0.252272      0.524623   \n",
      "5393  0.515306                 0.354559  0.250136  0.253393      0.523423   \n",
      "5680  0.517982                 0.353526  0.249408  0.252851      0.523383   \n",
      "5991  0.524095                 0.351358  0.249119  0.252944      0.524136   \n",
      "\n",
      "      val_root_mean_squared_error  learning_rate  \n",
      "266                      0.347188       0.000131  \n",
      "566                      0.347407       0.000188  \n",
      "886                      0.346831       0.000183  \n",
      "1169                     0.346952       0.000191  \n",
      "1471                     0.346861       0.000206  \n",
      "1787                     0.347199       0.000150  \n",
      "2088                     0.346978       0.000119  \n",
      "2391                     0.346775       0.000088  \n",
      "2697                     0.347193       0.000194  \n",
      "2999                     0.347130       0.000072  \n",
      "3294                     0.346892       0.000159  \n",
      "3570                     0.347201       0.000163  \n",
      "3885                     0.347803       0.000266  \n",
      "4172                     0.348190       0.000225  \n",
      "4498                     0.347076       0.000094  \n",
      "4782                     0.346655       0.000288  \n",
      "5082                     0.349369       0.000238  \n",
      "5393                     0.349945       0.000169  \n",
      "5680                     0.349903       0.000181  \n",
      "5991                     0.349727       0.000350  \n",
      "Best epochs per model:\n",
      "            layers activation  batch_size  epoch      loss       mae  \\\n",
      "254           [16]       relu          32    255  0.027181  0.249586   \n",
      "558           [16]       relu          64    259  0.027071  0.248823   \n",
      "795           [16]      prelu          32    196  0.027819  0.251335   \n",
      "1166          [16]      prelu          64    267  0.027065  0.249044   \n",
      "1446          [32]       relu          32    247  0.026679  0.247201   \n",
      "1761          [32]       relu          64    262  0.026660  0.247481   \n",
      "2039          [32]      prelu          32    240  0.026930  0.248220   \n",
      "2302          [32]      prelu          64    203  0.026934  0.248458   \n",
      "2624          [64]       relu          32    225  0.026790  0.248161   \n",
      "2925          [64]       relu          64    226  0.026443  0.246493   \n",
      "3251          [64]      prelu          32    252  0.026468  0.246949   \n",
      "3548          [64]      prelu          64    249  0.026506  0.247067   \n",
      "3874      [32, 16]       relu          32    275  0.027484  0.250482   \n",
      "4134      [32, 16]       relu          64    235  0.027796  0.250637   \n",
      "4444      [32, 16]      prelu          32    245  0.027393  0.249162   \n",
      "4744      [32, 16]      prelu          64    245  0.027386  0.249651   \n",
      "5057  [64, 32, 16]       relu          32    258  0.027506  0.248314   \n",
      "5327  [64, 32, 16]       relu          64    228  0.027490  0.249035   \n",
      "5696  [64, 32, 16]      prelu          32    297  0.026973  0.247649   \n",
      "5987  [64, 32, 16]      prelu          64    288  0.027023  0.247594   \n",
      "\n",
      "      r2_score  root_mean_squared_error  val_loss   val_mae  val_r2_score  \\\n",
      "254   0.542203                 0.339620  0.026221  0.243862      0.547012   \n",
      "558   0.544170                 0.338939  0.026118  0.243414      0.548170   \n",
      "795   0.531317                 0.343575  0.025903  0.243853      0.552166   \n",
      "1166  0.544246                 0.338890  0.026137  0.243893      0.548432   \n",
      "1446  0.550607                 0.336522  0.026121  0.243394      0.548437   \n",
      "1761  0.550975                 0.336358  0.026226  0.244021      0.546611   \n",
      "2039  0.546147                 0.338152  0.025870  0.242814      0.551953   \n",
      "2302  0.547020                 0.337920  0.025923  0.242701      0.551686   \n",
      "2624  0.549190                 0.337065  0.025980  0.243394      0.550592   \n",
      "2925  0.554829                 0.334943  0.026033  0.243231      0.549515   \n",
      "3251  0.554314                 0.335112  0.026091  0.243710      0.548527   \n",
      "3548  0.553247                 0.335530  0.025980  0.243679      0.549868   \n",
      "3874  0.539809                 0.340481  0.026316  0.243947      0.548073   \n",
      "4134  0.535929                 0.342067  0.026451  0.243440      0.546420   \n",
      "4444  0.542120                 0.339580  0.026086  0.243149      0.552608   \n",
      "4744  0.542184                 0.339640  0.026150  0.243390      0.550547   \n",
      "5057  0.547138                 0.337889  0.027013  0.244813      0.542998   \n",
      "5327  0.547333                 0.337712  0.027028  0.244738      0.544044   \n",
      "5696  0.552016                 0.335944  0.026580  0.244152      0.546639   \n",
      "5987  0.551288                 0.336250  0.026607  0.244318      0.545746   \n",
      "\n",
      "      val_root_mean_squared_error  learning_rate  \n",
      "254                      0.333109       0.000063  \n",
      "558                      0.332554       0.000100  \n",
      "795                      0.331052       0.000350  \n",
      "1166                     0.332577       0.000038  \n",
      "1446                     0.332581       0.000063  \n",
      "1761                     0.333199       0.000031  \n",
      "2039                     0.331044       0.000163  \n",
      "2302                     0.331145       0.000225  \n",
      "2624                     0.331558       0.000125  \n",
      "2925                     0.331979       0.000125  \n",
      "3251                     0.332351       0.000034  \n",
      "3548                     0.331827       0.000075  \n",
      "3874                     0.332657       0.000056  \n",
      "4134                     0.333199       0.000113  \n",
      "4444                     0.330877       0.000138  \n",
      "4744                     0.331461       0.000125  \n",
      "5057                     0.334402       0.000088  \n",
      "5327                     0.334286       0.000138  \n",
      "5696                     0.333038       0.000025  \n",
      "5987                     0.333248       0.000031  \n",
      "Best epochs per model:\n",
      "            layers activation  batch_size  epoch      loss       mae  \\\n",
      "288           [16]       relu          32    289  0.026817  0.256034   \n",
      "566           [16]       relu          64    267  0.026854  0.255969   \n",
      "886           [16]      prelu          32    287  0.026637  0.255945   \n",
      "1198          [16]      prelu          64    299  0.026627  0.256366   \n",
      "1443          [32]       relu          32    244  0.026320  0.253962   \n",
      "1784          [32]       relu          64    285  0.026297  0.255078   \n",
      "2063          [32]      prelu          32    264  0.026212  0.253804   \n",
      "2385          [32]      prelu          64    286  0.026263  0.253327   \n",
      "2680          [64]       relu          32    281  0.025940  0.252285   \n",
      "2990          [64]       relu          64    291  0.025913  0.253314   \n",
      "3294          [64]      prelu          32    295  0.025981  0.253181   \n",
      "3538          [64]      prelu          64    239  0.025938  0.252801   \n",
      "3874      [32, 16]       relu          32    275  0.026931  0.256508   \n",
      "4172      [32, 16]       relu          64    273  0.026662  0.255116   \n",
      "4498      [32, 16]      prelu          32    299  0.026744  0.255556   \n",
      "4797      [32, 16]      prelu          64    298  0.026984  0.256882   \n",
      "5058  [64, 32, 16]       relu          32    259  0.026853  0.254188   \n",
      "5362  [64, 32, 16]       relu          64    263  0.026914  0.254392   \n",
      "5665  [64, 32, 16]      prelu          32    266  0.026724  0.254101   \n",
      "5978  [64, 32, 16]      prelu          64    279  0.026732  0.254182   \n",
      "\n",
      "      r2_score  root_mean_squared_error  val_loss   val_mae  val_r2_score  \\\n",
      "288   0.512834                 0.355494  0.025735  0.250648      0.531408   \n",
      "566   0.512070                 0.355684  0.025750  0.250751      0.531394   \n",
      "886   0.515844                 0.354401  0.025690  0.251395      0.531796   \n",
      "1198  0.516130                 0.354268  0.025538  0.250423      0.534615   \n",
      "1443  0.521586                 0.352292  0.025632  0.250518      0.532704   \n",
      "1784  0.521968                 0.352125  0.025554  0.250220      0.534226   \n",
      "2063  0.523777                 0.351494  0.025550  0.250854      0.534316   \n",
      "2385  0.522563                 0.351895  0.025580  0.250708      0.533493   \n",
      "2680  0.528838                 0.349590  0.025612  0.250858      0.533192   \n",
      "2990  0.528969                 0.349545  0.025583  0.250818      0.533364   \n",
      "3294  0.527827                 0.349951  0.025551  0.250922      0.534013   \n",
      "3538  0.528806                 0.349605  0.025606  0.250759      0.533360   \n",
      "3874  0.513466                 0.355260  0.026006  0.251122      0.528323   \n",
      "4172  0.519463                 0.353063  0.025960  0.251269      0.529837   \n",
      "4498  0.518189                 0.353553  0.025884  0.250613      0.532018   \n",
      "4797  0.512720                 0.355506  0.025782  0.251037      0.533072   \n",
      "5058  0.521396                 0.352370  0.026583  0.253553      0.523492   \n",
      "5362  0.519501                 0.353013  0.026332  0.252409      0.528030   \n",
      "5665  0.521952                 0.352162  0.026239  0.251709      0.528922   \n",
      "5978  0.521942                 0.352104  0.026238  0.251571      0.529213   \n",
      "\n",
      "      val_root_mean_squared_error  learning_rate  \n",
      "288                      0.347235       0.000020  \n",
      "566                      0.347259       0.000044  \n",
      "886                      0.347083       0.000028  \n",
      "1198                     0.345974       0.000019  \n",
      "1443                     0.346720       0.000056  \n",
      "1784                     0.346175       0.000022  \n",
      "2063                     0.346092       0.000050  \n",
      "2385                     0.346386       0.000025  \n",
      "2680                     0.346491       0.000028  \n",
      "2990                     0.346428       0.000025  \n",
      "3294                     0.346184       0.000016  \n",
      "3538                     0.346454       0.000069  \n",
      "3874                     0.348191       0.000044  \n",
      "4172                     0.347562       0.000050  \n",
      "4498                     0.346866       0.000034  \n",
      "4797                     0.346508       0.000025  \n",
      "5058                     0.349892       0.000069  \n",
      "5362                     0.348307       0.000056  \n",
      "5665                     0.348006       0.000056  \n",
      "5978                     0.347895       0.000066  \n"
     ]
    }
   ],
   "source": [
    "for (scale, preprocessing, data_type) in product(['standardized', 'normalized'], ['preprocessed', 'non_processed'], ['external']):\n",
    "    optimal_models = filter_models(data[(scale, preprocessing, data_type)])\n",
    "\n",
    "    print(\"Best epochs per model:\")\n",
    "    print(optimal_models)\n",
    "\n",
    "    optimal_models.to_csv(f\"../reports/results/training/{scale}/non_engineered/{preprocessing}/{data_type}/optimal_models.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmented Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epochs per model:\n",
      "            layers activation  batch_size  epoch      loss       mae  \\\n",
      "242           [16]       relu          32    243  0.249227  0.258006   \n",
      "583           [16]       relu          64    284  0.250013  0.258622   \n",
      "822           [16]      prelu          32    223  0.250192  0.258921   \n",
      "1192          [16]      prelu          64    293  0.248061  0.257720   \n",
      "1412          [32]       relu          32    213  0.246026  0.256713   \n",
      "1758          [32]       relu          64    259  0.246255  0.256716   \n",
      "2085          [32]      prelu          32    286  0.245298  0.256868   \n",
      "2360          [32]      prelu          64    261  0.244786  0.256448   \n",
      "2645          [64]       relu          32    246  0.242958  0.255763   \n",
      "2946          [64]       relu          64    247  0.243095  0.255664   \n",
      "3248          [64]      prelu          32    249  0.242028  0.255278   \n",
      "3585          [64]      prelu          64    286  0.241518  0.254942   \n",
      "3884      [32, 16]       relu          32    285  0.256612  0.260490   \n",
      "4186      [32, 16]       relu          64    287  0.255888  0.260037   \n",
      "4494      [32, 16]      prelu          32    295  0.252236  0.259683   \n",
      "4755      [32, 16]      prelu          64    256  0.252811  0.259545   \n",
      "5032  [64, 32, 16]       relu          32    233  0.249736  0.257228   \n",
      "5372  [64, 32, 16]       relu          64    273  0.248604  0.257015   \n",
      "5692  [64, 32, 16]      prelu          32    293  0.244708  0.255441   \n",
      "5962  [64, 32, 16]      prelu          64    263  0.244460  0.255213   \n",
      "\n",
      "      r2_score  root_mean_squared_error  val_loss   val_mae  val_r2_score  \\\n",
      "242   0.517891                 0.358761  0.234888  0.251602      0.545298   \n",
      "583   0.516405                 0.359319  0.234860  0.251718      0.545347   \n",
      "822   0.516041                 0.359438  0.235200  0.252031      0.544702   \n",
      "1192  0.520039                 0.357961  0.235232  0.252114      0.544504   \n",
      "1412  0.524119                 0.356441  0.234087  0.251207      0.546861   \n",
      "1758  0.523630                 0.356621  0.234023  0.251116      0.546941   \n",
      "2085  0.525446                 0.355945  0.234991  0.251848      0.545007   \n",
      "2360  0.526358                 0.355596  0.234420  0.251544      0.546083   \n",
      "2645  0.529936                 0.354255  0.233072  0.250649      0.548804   \n",
      "2946  0.529678                 0.354351  0.233556  0.250960      0.547817   \n",
      "3248  0.531747                 0.353570  0.232814  0.250601      0.549327   \n",
      "3585  0.532740                 0.353194  0.231872  0.250006      0.551157   \n",
      "3884  0.505784                 0.363241  0.235176  0.250485      0.546835   \n",
      "4186  0.507481                 0.362613  0.234723  0.250259      0.547947   \n",
      "4494  0.514575                 0.359998  0.237779  0.252075      0.542107   \n",
      "4755  0.513368                 0.360443  0.237192  0.252071      0.543229   \n",
      "5032  0.521833                 0.357296  0.239097  0.250197      0.542029   \n",
      "5372  0.523813                 0.356532  0.238818  0.249949      0.542359   \n",
      "5692  0.530780                 0.353906  0.240003  0.250118      0.539421   \n",
      "5962  0.531378                 0.353696  0.239611  0.249946      0.540352   \n",
      "\n",
      "      val_root_mean_squared_error  learning_rate  \n",
      "242                      0.348113       0.000028  \n",
      "583                      0.348084       0.000014  \n",
      "822                      0.348326       0.000034  \n",
      "1192                     0.348401       0.000009  \n",
      "1412                     0.347511       0.000050  \n",
      "1758                     0.347481       0.000034  \n",
      "2085                     0.348208       0.000005  \n",
      "2360                     0.347809       0.000047  \n",
      "2645                     0.346788       0.000075  \n",
      "2946                     0.347152       0.000031  \n",
      "3248                     0.346591       0.000083  \n",
      "3585                     0.345897       0.000233  \n",
      "3884                     0.347511       0.000033  \n",
      "4186                     0.347060       0.000052  \n",
      "4494                     0.349325       0.000016  \n",
      "4755                     0.348919       0.000044  \n",
      "5032                     0.349336       0.000034  \n",
      "5372                     0.349233       0.000022  \n",
      "5692                     0.350324       0.000009  \n",
      "5962                     0.349992       0.000017  \n",
      "Best epochs per model:\n",
      "            layers activation  batch_size  epoch      loss       mae  \\\n",
      "280           [16]       relu          32    281  0.267718  0.266592   \n",
      "566           [16]       relu          64    267  0.268138  0.266643   \n",
      "884           [16]      prelu          32    285  0.267274  0.266710   \n",
      "1195          [16]      prelu          64    296  0.267143  0.266285   \n",
      "1441          [32]       relu          32    242  0.263376  0.265269   \n",
      "1773          [32]       relu          64    274  0.263370  0.264873   \n",
      "2089          [32]      prelu          32    290  0.262238  0.264585   \n",
      "2367          [32]      prelu          64    268  0.262028  0.264609   \n",
      "2660          [64]       relu          32    261  0.260122  0.263846   \n",
      "2969          [64]       relu          64    270  0.260500  0.263884   \n",
      "3298          [64]      prelu          32    299  0.259656  0.263546   \n",
      "3565          [64]      prelu          64    266  0.259568  0.263272   \n",
      "3887      [32, 16]       relu          32    288  0.272125  0.267731   \n",
      "4179      [32, 16]       relu          64    280  0.273218  0.268356   \n",
      "4494      [32, 16]      prelu          32    295  0.268189  0.267182   \n",
      "4760      [32, 16]      prelu          64    261  0.269593  0.267209   \n",
      "5086  [64, 32, 16]       relu          32    287  0.267690  0.265634   \n",
      "5393  [64, 32, 16]       relu          64    294  0.265700  0.265009   \n",
      "5699  [64, 32, 16]      prelu          32    300  0.261905  0.263955   \n",
      "5996  [64, 32, 16]      prelu          64    297  0.263026  0.264159   \n",
      "\n",
      "      r2_score  root_mean_squared_error  val_loss   val_mae  val_r2_score  \\\n",
      "280   0.493281                 0.375924  0.252619  0.259930      0.520230   \n",
      "566   0.492562                 0.376168  0.253184  0.259947      0.519382   \n",
      "884   0.494019                 0.375656  0.253110  0.260228      0.519320   \n",
      "1195  0.494365                 0.375506  0.252945  0.259953      0.519711   \n",
      "1441  0.501529                 0.372840  0.252267  0.260165      0.520897   \n",
      "1773  0.501569                 0.372840  0.252110  0.259775      0.521212   \n",
      "2089  0.503578                 0.372090  0.252576  0.259991      0.520299   \n",
      "2367  0.504013                 0.371928  0.252487  0.260029      0.520488   \n",
      "2660  0.507604                 0.370569  0.252480  0.260159      0.520405   \n",
      "2969  0.506868                 0.370836  0.252159  0.259906      0.521016   \n",
      "3298  0.508493                 0.370232  0.251270  0.259562      0.522630   \n",
      "3565  0.508663                 0.370175  0.251775  0.259777      0.521714   \n",
      "3887  0.487339                 0.378140  0.254120  0.258593      0.519907   \n",
      "4179  0.485165                 0.378907  0.253824  0.258966      0.520368   \n",
      "4494  0.494902                 0.375344  0.255117  0.259460      0.518011   \n",
      "4760  0.492290                 0.376300  0.254795  0.259209      0.518765   \n",
      "5086  0.497755                 0.374248  0.256562  0.258105      0.517477   \n",
      "5393  0.501529                 0.372863  0.257707  0.258604      0.515309   \n",
      "5699  0.507922                 0.370466  0.256961  0.257643      0.515975   \n",
      "5996  0.505961                 0.371191  0.257140  0.257841      0.515739   \n",
      "\n",
      "      val_root_mean_squared_error  learning_rate  \n",
      "280                      0.364977       0.000021  \n",
      "566                      0.365323       0.000011  \n",
      "884                      0.365357       0.000017  \n",
      "1195                     0.365200       0.000011  \n",
      "1441                     0.364718       0.000058  \n",
      "1773                     0.364600       0.000013  \n",
      "2089                     0.364971       0.000010  \n",
      "2367                     0.364897       0.000020  \n",
      "2660                     0.364908       0.000019  \n",
      "2969                     0.364676       0.000025  \n",
      "3298                     0.364042       0.000075  \n",
      "3565                     0.364402       0.000059  \n",
      "3887                     0.365137       0.000039  \n",
      "4179                     0.364941       0.000048  \n",
      "4494                     0.365827       0.000046  \n",
      "4760                     0.365565       0.000072  \n",
      "5086                     0.366076       0.000095  \n",
      "5393                     0.366945       0.000027  \n",
      "5699                     0.366683       0.000032  \n",
      "5996                     0.366761       0.000023  \n",
      "Best epochs per model:\n",
      "            layers activation  batch_size  epoch      loss       mae  \\\n",
      "242           [16]       relu          32    243  0.030017  0.257662   \n",
      "578           [16]       relu          64    279  0.030041  0.258174   \n",
      "822           [16]      prelu          32    223  0.029866  0.257122   \n",
      "1153          [16]      prelu          64    254  0.029933  0.257501   \n",
      "1412          [32]       relu          32    213  0.029603  0.256376   \n",
      "1725          [32]       relu          64    226  0.029545  0.255873   \n",
      "2078          [32]      prelu          32    279  0.029403  0.255501   \n",
      "2360          [32]      prelu          64    261  0.029395  0.255381   \n",
      "2652          [64]       relu          32    253  0.029115  0.254467   \n",
      "2978          [64]       relu          64    279  0.029141  0.254784   \n",
      "3238          [64]      prelu          32    239  0.029169  0.255014   \n",
      "3580          [64]      prelu          64    281  0.029195  0.255030   \n",
      "3856      [32, 16]       relu          32    257  0.030398  0.258928   \n",
      "4117      [32, 16]       relu          64    218  0.030221  0.258156   \n",
      "4494      [32, 16]      prelu          32    295  0.029835  0.256940   \n",
      "4722      [32, 16]      prelu          64    223  0.029987  0.257281   \n",
      "5096  [64, 32, 16]       relu          32    297  0.030324  0.257456   \n",
      "5344  [64, 32, 16]       relu          64    245  0.030581  0.257964   \n",
      "5679  [64, 32, 16]      prelu          32    280  0.029966  0.256255   \n",
      "5989  [64, 32, 16]      prelu          64    290  0.029952  0.255935   \n",
      "\n",
      "      r2_score  root_mean_squared_error  val_loss   val_mae  val_r2_score  \\\n",
      "242   0.518950                 0.358367  0.028265  0.251661      0.546687   \n",
      "578   0.518468                 0.358537  0.028341  0.251852      0.545422   \n",
      "822   0.521454                 0.357427  0.028207  0.251034      0.547899   \n",
      "1153  0.520323                 0.357863  0.028266  0.251261      0.546703   \n",
      "1412  0.525650                 0.355863  0.028259  0.251498      0.546861   \n",
      "1725  0.526634                 0.355499  0.028120  0.250983      0.549147   \n",
      "2078  0.529009                 0.354603  0.028154  0.250966      0.548646   \n",
      "2360  0.529123                 0.354553  0.028104  0.250693      0.549685   \n",
      "2652  0.533849                 0.352773  0.027933  0.250034      0.552387   \n",
      "2978  0.533392                 0.352941  0.028010  0.250689      0.551242   \n",
      "3238  0.532757                 0.353182  0.028082  0.250692      0.550028   \n",
      "3580  0.532274                 0.353373  0.028154  0.250881      0.548522   \n",
      "3856  0.514622                 0.359984  0.028171  0.250026      0.549887   \n",
      "4117  0.517719                 0.358819  0.028188  0.249758      0.549755   \n",
      "4494  0.524046                 0.356466  0.028119  0.249924      0.551239   \n",
      "4722  0.521156                 0.357547  0.028231  0.250595      0.548914   \n",
      "5096  0.520245                 0.357881  0.028513  0.250055      0.549035   \n",
      "5344  0.515896                 0.359513  0.028407  0.249777      0.550448   \n",
      "5679  0.525823                 0.355796  0.028422  0.249974      0.550228   \n",
      "5989  0.525424                 0.355944  0.028402  0.250269      0.549960   \n",
      "\n",
      "      val_root_mean_squared_error  learning_rate  \n",
      "242                      0.347590       0.000006  \n",
      "578                      0.348072       0.000003  \n",
      "822                      0.347153       0.000011  \n",
      "1153                     0.347583       0.000005  \n",
      "1412                     0.347522       0.000011  \n",
      "1725                     0.346633       0.000014  \n",
      "2078                     0.346843       0.000003  \n",
      "2360                     0.346485       0.000005  \n",
      "2652                     0.345375       0.000008  \n",
      "2978                     0.345880       0.000002  \n",
      "3238                     0.346352       0.000008  \n",
      "3580                     0.346850       0.000002  \n",
      "3856                     0.346325       0.000006  \n",
      "4117                     0.346334       0.000023  \n",
      "4494                     0.345827       0.000002  \n",
      "4722                     0.346709       0.000009  \n",
      "5096                     0.346706       0.000002  \n",
      "5344                     0.346168       0.000007  \n",
      "5679                     0.346219       0.000004  \n",
      "5989                     0.346334       0.000002  \n",
      "Best epochs per model:\n",
      "            layers activation  batch_size  epoch      loss       mae  \\\n",
      "214           [16]       relu          32    215  0.029712  0.266681   \n",
      "566           [16]       relu          64    267  0.029814  0.267555   \n",
      "855           [16]      prelu          32    256  0.029606  0.266601   \n",
      "1166          [16]      prelu          64    267  0.029530  0.266194   \n",
      "1467          [32]       relu          32    268  0.029290  0.265906   \n",
      "1702          [32]       relu          64    203  0.029290  0.265518   \n",
      "2082          [32]      prelu          32    283  0.029053  0.264960   \n",
      "2348          [32]      prelu          64    249  0.029126  0.264895   \n",
      "2683          [64]       relu          32    284  0.028863  0.263991   \n",
      "2969          [64]       relu          64    270  0.028888  0.263931   \n",
      "3270          [64]      prelu          32    271  0.028835  0.263732   \n",
      "3565          [64]      prelu          64    266  0.028828  0.263800   \n",
      "3874      [32, 16]       relu          32    275  0.030005  0.267429   \n",
      "4178      [32, 16]       relu          64    279  0.029755  0.266254   \n",
      "4471      [32, 16]      prelu          32    272  0.029514  0.265574   \n",
      "4742      [32, 16]      prelu          64    243  0.029487  0.265995   \n",
      "5052  [64, 32, 16]       relu          32    253  0.030013  0.265952   \n",
      "5331  [64, 32, 16]       relu          64    232  0.030137  0.267451   \n",
      "5628  [64, 32, 16]      prelu          32    229  0.029609  0.264805   \n",
      "5997  [64, 32, 16]      prelu          64    298  0.029576  0.265021   \n",
      "\n",
      "      r2_score  root_mean_squared_error  val_loss   val_mae  val_r2_score  \\\n",
      "214   0.491751                 0.376509  0.027983  0.260320      0.519730   \n",
      "566   0.489920                 0.377155  0.028078  0.260608      0.518186   \n",
      "855   0.493662                 0.375784  0.028054  0.260155      0.518799   \n",
      "1166  0.494859                 0.375338  0.028002  0.260232      0.519401   \n",
      "1467  0.498803                 0.373870  0.028015  0.260220      0.519059   \n",
      "1702  0.498814                 0.373853  0.028039  0.260711      0.518721   \n",
      "2082  0.503034                 0.372274  0.027916  0.259815      0.521092   \n",
      "2348  0.501703                 0.372789  0.027907  0.260113      0.520958   \n",
      "2683  0.506404                 0.371029  0.027731  0.258913      0.524297   \n",
      "2969  0.505915                 0.371177  0.027825  0.259355      0.522783   \n",
      "3270  0.506806                 0.370884  0.027824  0.259448      0.522320   \n",
      "3565  0.506832                 0.370869  0.027887  0.259838      0.521281   \n",
      "3874  0.489241                 0.377438  0.028262  0.258992      0.517587   \n",
      "4178  0.493842                 0.375692  0.028197  0.258844      0.518872   \n",
      "4471  0.497554                 0.374348  0.028134  0.259018      0.519589   \n",
      "4742  0.497870                 0.374219  0.027999  0.259508      0.521750   \n",
      "5052  0.493206                 0.375952  0.028376  0.258902      0.519557   \n",
      "5331  0.490889                 0.376797  0.028381  0.259321      0.519434   \n",
      "5628  0.499401                 0.373660  0.028325  0.259495      0.519754   \n",
      "5997  0.499290                 0.373693  0.028259  0.259044      0.520219   \n",
      "\n",
      "      val_root_mean_squared_error  learning_rate  \n",
      "214                      0.365185       0.000011  \n",
      "566                      0.365803       0.000002  \n",
      "855                      0.365587       0.000004  \n",
      "1166                     0.365317       0.000003  \n",
      "1467                     0.365458       0.000002  \n",
      "1702                     0.365586       0.000014  \n",
      "2082                     0.364724       0.000002  \n",
      "2348                     0.364721       0.000005  \n",
      "2683                     0.363468       0.000002  \n",
      "2969                     0.364092       0.000002  \n",
      "3270                     0.364187       0.000002  \n",
      "3565                     0.364598       0.000002  \n",
      "3874                     0.366070       0.000003  \n",
      "4178                     0.365492       0.000003  \n",
      "4471                     0.365282       0.000004  \n",
      "4742                     0.364420       0.000007  \n",
      "5052                     0.365208       0.000005  \n",
      "5331                     0.365270       0.000017  \n",
      "5628                     0.365172       0.000014  \n",
      "5997                     0.365000       0.000002  \n"
     ]
    }
   ],
   "source": [
    "for (scale, preprocessing, data_type) in product(['standardized', 'normalized'], ['preprocessed', 'non_processed'], ['augmented']):\n",
    "    optimal_models = filter_models(data[(scale, preprocessing, data_type)])\n",
    "\n",
    "    print(\"Best epochs per model:\")\n",
    "    print(optimal_models)\n",
    "\n",
    "    optimal_models.to_csv(f\"../reports/results/training/{scale}/non_engineered/{preprocessing}/{data_type}/optimal_models.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
