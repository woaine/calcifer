layers,activation,batch_size,mae,mae_lower,mae_upper,rmse,rmse_lower,rmse_upper
64,prelu,32,0.2611351878023784,0.2502478791505261,0.2720834921474467,0.36595486381786224,0.34664775061164427,0.3834045128911128
